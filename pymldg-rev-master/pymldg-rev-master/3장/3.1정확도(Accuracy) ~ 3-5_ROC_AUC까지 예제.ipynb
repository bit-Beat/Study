{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1 Accuracy(정확도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit( ) 메소드는 아무것도 학습하지 않음. \n",
    "    def fit(self, X , y=None):\n",
    "        pass\n",
    "    \n",
    "    # predict( ) 메소드는 단순히 Sex feature가 1 이면 0 , 그렇지 않으면 1 로 예측함. \n",
    "    def predict(self, X):\n",
    "        pred = np.zeros( ( X.shape[0], 1 ))\n",
    "        for i in range (X.shape[0]) :\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는: 0.7877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. \n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                  test_size=0.2, random_state=0)\n",
    "\n",
    "# 위에서 생성한 Dummy Classifier를 이용하여 학습/예측/평가 수행. \n",
    "myclf = MyDummyClassifier()\n",
    "# myclf.fit(X_train ,y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test , mypredictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "### digits.data.shape: (1797, 64)\n",
      "[0 1 2 ... 8 9 8]\n",
      "### digits.target.shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X 데이터 셋의 크기만큼 모두 0값으로 만들어서 반환\n",
    "    def predict(self,X):\n",
    "        return np.zeros( (len(X), 1) , dtype=bool)\n",
    "\n",
    "# 사이킷런의 내장 데이터 셋인 load_digits( )를 이용하여 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.data)\n",
    "print(\"### digits.data.shape:\", digits.data.shape)\n",
    "print(digits.target)\n",
    "print(\"### digits.target.shape:\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7번이 아니면 False이고 0으로 변환. \n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split( digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기 : (450,)\n",
      "테스트 세트 레이블 0 과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인. \n",
    "print('레이블 테스트 세트 크기 :', y_test.shape)\n",
    "print('테스트 세트 레이블 0 과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train , y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test , fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5972/2686397780.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 앞절의 예측 결과인 fakepred와 실제 결과인 y_test의 Confusion Matrix출력\n",
    "confusion_matrix(y_test , fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정밀도(Precision) 과 재현율(Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** MyFakeClassifier의 예측 결과로 정밀도와 재현율 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도: 0.0\n",
      "재현율: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DJ\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score\n",
    "\n",
    "print(\"정밀도:\", precision_score(y_test, fakepred)) # 예측값이 False \n",
    "print(\"재현율:\", recall_score(y_test, fakepred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 오차행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수 생성 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy , precision ,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. \n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                    test_size=0.20, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train , y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "matrix = get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision/Recall Trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** predict_proba( ) 메소드 확인 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 Shape : (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.46190458 0.53809542]\n",
      " [0.87861171 0.12138829]\n",
      " [0.87716568 0.12283432]]\n",
      "두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.46190458 0.53809542 1.        ]\n",
      " [0.87861171 0.12138829 0.        ]\n",
      " [0.87716568 0.12283432 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred  = lr_clf.predict(X_test)\n",
    "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba , pred.reshape(-1,1)],axis=1)\n",
    "print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n',pred_proba_result[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Binarizer 활용 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer ## 바이너라이저\n",
    "\n",
    "X = [[ 1, -1,  2],\n",
    "     [ 2,  0,  0],\n",
    "     [ 0,  1.1, 1.2]]\n",
    "\n",
    "# threshold 기준값보다 같거나 작으면 0을, 크면 1을 반환\n",
    "binarizer = Binarizer(threshold=1.1)                     \n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, -1, 2], [2, 0, 0], [0, 1.1, 1.2]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binarizer(threshold=1.1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 분류 결정 임계값 0.5 기반에서 Binarizer를 이용하여 예측값 변환 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#Binarizer의 threshold 설정값. 분류 결정 임곗값임.  \n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba( ) 반환값의 두번째 컬럼 , 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=0.6).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431    1\n",
       "821    1\n",
       "629    0\n",
       "626    0\n",
       "665    0\n",
       "      ..\n",
       "638    0\n",
       "771    0\n",
       "521    0\n",
       "711    0\n",
       "484    1\n",
       "Name: Survived, Length: 179, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 분류 결정 임계값 0.4 기반에서 Binarizer를 이용하여 예측값 변환 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361\n"
     ]
    }
   ],
   "source": [
    "# Binarizer의 threshold 설정값을 0.4로 설정. 즉 분류 결정 임곗값을 0.5에서 0.4로 낮춤  \n",
    "custom_threshold = 0.4\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test , custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 여러개의 분류 결정 임곗값을 변경하면서  Binarizer를 이용하여 예측값 변환 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "오차 행렬\n",
      "[[98 20]\n",
      " [10 51]]\n",
      "정확도: 0.8324, 정밀도: 0.7183, 재현율: 0.8361\n",
      "임곗값: 0.45\n",
      "오차 행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도: 0.8492, 정밀도: 0.7656, 재현율: 0.8033\n",
      "임곗값: 0.5\n",
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n",
      "임곗값: 0.55\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도: 0.8659, 정밀도: 0.8364, 재현율: 0.7541\n",
      "임곗값: 0.6\n",
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377\n"
     ]
    }
   ],
   "source": [
    "# 테스트를 수행할 모든 임곗값을 리스트 객체로 저장. \n",
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "\n",
    "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
    "    # thresholds list객체내의 값을 차례로 iteration하면서 Evaluation 수행.\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임곗값:',custom_threshold)\n",
    "        get_clf_eval(y_test , custom_predict)\n",
    "\n",
    "get_eval_by_threshold(y_test ,pred_proba[:,1].reshape(-1,1), thresholds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** precision_recall_curve( ) 를 이용하여 임곗값에 따른 정밀도-재현율 값 추출 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반환된 분류 결정 임곗값 배열의 Shape: (143,)\n",
      "반환된 precisions 배열의 Shape: (144,)\n",
      "반환된 recalls 배열의 Shape: (144,)\n",
      "thresholds 5 sample: [0.10396779 0.10397004 0.10399526 0.10772288 0.10894545]\n",
      "precisions 5 sample: [0.38853503 0.38461538 0.38709677 0.38961039 0.38562092]\n",
      "recalls 5 sample: [1.         0.98360656 0.98360656 0.98360656 0.96721311]\n",
      "샘플 추출을 위한 임계값 배열의 index 10개: [  0  15  30  45  60  75  90 105 120 135]\n",
      "샘플용 10개의 임곗값:  [0.1  0.12 0.14 0.19 0.28 0.4  0.56 0.67 0.82 0.95]\n",
      "샘플 임계값별 정밀도:  [0.389 0.44  0.466 0.539 0.647 0.729 0.836 0.949 0.958 1.   ]\n",
      "샘플 임계값별 재현율:  [1.    0.967 0.902 0.902 0.902 0.836 0.754 0.607 0.377 0.148]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "# 실제값 데이터 셋과 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력 \n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1 )\n",
    "print('반환된 분류 결정 임곗값 배열의 Shape:', thresholds.shape)\n",
    "print('반환된 precisions 배열의 Shape:', precisions.shape)\n",
    "print('반환된 recalls 배열의 Shape:', recalls.shape)\n",
    "\n",
    "print(\"thresholds 5 sample:\", thresholds[:5])\n",
    "print(\"precisions 5 sample:\", precisions[:5])\n",
    "print(\"recalls 5 sample:\", recalls[:5])\n",
    "\n",
    "#반환된 임계값 배열 로우가 147건이므로 샘플로 10건만 추출하되, 임곗값을 15 Step으로 추출. \n",
    "thr_index = np.arange(0, thresholds.shape[0], 15)\n",
    "print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값 \n",
    "print('샘플 임계값별 정밀도: ', np.round(precisions[thr_index], 3))\n",
    "print('샘플 임계값별 재현율: ', np.round(recalls[thr_index], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 임곗값의 변경에 따른 정밀도-재현율 변화 곡선을 그림 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(y_test, lr_clf.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAFzCAYAAAAuSjCuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABO0UlEQVR4nO3dd3xV9f3H8dcne5IECGHvvbcoQ3CCe6CorXvWam2tddRWba39WbWtteIeuKri3lsQRRRE9hRkg4xAQkJ28v39cS4YIIEL5Obcm7yfj8d93HvGPfedq+ST7znf8/2acw4RERGJPFF+BxAREZGDoyIuIiISoVTERUREIpSKuIiISIRSERcREYlQKuIiIiIRKsbvAAcqPT3ddezY0e8YB2XHjh0kJyf7HeOgKLt/Ijm/svtD2f0RyuwzZ87c4pzL3HN9xBXxrKwsvvvuO79jHJTJkyczcuRIv2McFGX3TyTnV3Z/KLs/QpndzFZVtV6n00VERCKUiriIiEiEUhEXERGJUCriIiIiEUpFXEREJEKpiIuIiEQoFXEREZEIpSIuIiISoVTERUREIlTIiriZPWVmm8xsfjXbzcweMLNlZjbXzPqHKouIiEhdFMqW+ARg9D62jwE6BR5XAA+HMIuIiEidE7Kx051zU8ys7T52ORV41jnngG/MLN3MmjnnNoQqU5VWToX4VGjWu1Y/VkRE/FNQUsaMlds4srM3p8jin7azIbdot32izRgR2L5gfS6b8op32x4fHcURHRsDMHdtDnM3l+GWbKJH8wY0SU2ohZ8CzKuhITq4V8Tfdc71rGLbu8DdzrmvAsufATc55/aa3cTMrsBrrZOZmTlg4sSJNZZx8Le/Ii+1A4u631Bjx6xOfn4+KSkpIf+cUFB2/0RyfmX3h7Lv36tLS3j3x1ImjPZmHXtqfjFT1pbttk9CNDxyrLf9odlFTP+pfLft6fHG/aOSAPj3zCLmbPa2/7pvPIOa1mwbedSoUTOdcwP3XO/nLGZWxboq/6Jwzj0GPAbQpUsXV6OzxMxNJKlJE7JqYdYczc7jj0jODpGdX9n9oez799DiaTRMzt/1We17FZC9Y/eWdnSU0btlOgBteu4gp6Bkt+2x0VH0bJEGQKse+Uye+i39+/enbaNkMpLjQv4zgL9FfC3QqtJyS2B9racwgxCejRARkfBSVl7BvHW5jBv0cwlq3SiJ1o2Sqn1Pu8bJQPVzhXfITGFNejT9WmfUZNT98vMWs7eBCwK91IcAubV+PRzwTgioiIuI1BdLNuZRWFpOv9bpfkc5ZCFriZvZi8BIoLGZrQVuB2IBnHOPAO8DJwDLgALg4lBl2a/8zbDqa2g5CKJjfYshIiKhN2t1DgD9WtVuqzkUQtk7/dz9bHfAr0P1+UFLaACrvoKnx8DJ/4EBF/mdSEREQujsga3o3TKNVg0T/Y5yyDRi2zkvwkXvQ3Q8ZC/3O42IiIRYXEwUvVumY1ZV/+rIoiKemgVth0KD5rB9nd9pREQkhLYXlfLXdxaydGOe31FqhIr4TmktIXet3ylERCSE5q7J5ampK9i4vWj/O0cAP28xCy9pLWH557Bq2t7bGraD1Ka1n0lEpIY55ygoKScpLrpOnE4+ULPXbAPYdf93pFMR36lhB5jzIjxdxXDvTbrD1VUUdxGRCPP2nPVc99JsogxS4mNITYglNSGGW07oxpGdMymvcBgQFVU3C/zsNTl0yEwmLbFu3ImkIr7TEddAq8HgKnZfP+dFmP8alJdBtL4uEYlMuQWlpCXFckqf5mzdUcLWHSXkFZWRV1RGfnEpKfHe77d3567nL+8spFVGIk3TEmiWlkhmajznH96GBgmxrM8pZFtBCelJcaQnxpIcHzm/F51zzF6Tw5Gdm/gdpcZEzrcfarGJ0P7IvdfnroG5L8P2tZDRttZjiYgciooKx0OTl/H4lyt4+5qhtGmUzMVD21W7f8PkOI7p1oQNuUX8uHkHU5dlk19cxrmDWwPwwrerGD/p5zt5WjdMYmjHxvz5pG4kxYV3Sdm6wxs2tW8dGORlp/D+xsNBRuB/9q0rVMRFJKLkFJRw/cQ5fL54E6f3a0Fmavx+3zO8UybDO2Xutq6wpJyEWK8f9Jn9W9KrRTq5hSVsyS9h1uocpq/IJjE2GoCPFvxEWmIs3Zs3oEFCeJ2ybpQSz4xbj6G8ou6M0qkivj87C/e2lX6mEJEQm7s2h+z8EhoketeJc4or9v+mMDZvbS6/emEmG7cXcedpPfnlYa0PuiNbYlz0rtftM1Non7n7LGPOOcyMotJybn1jHlvyvRZv64ZJdM5K5ehuTXa15N+ft4G0xFgapcTRMDmOhklxxETX3o1SZkZMdN253q8ivj8NmoNFe6fVRaROKiwpZ+zD0ygp/7lwt06N4rTjvdfZ+cXExUSREh8TMT26/zd9FRUVjleuOoK+rdJD+lk7v5OE2Gg++d2RzF6bw8L121m4fjvLNuWzdlsBACVlFVz9wvd7vf/Xozrwh+O7UlhSzn9nFfHJtnk0So6jUUo8DZPj6NUijbaNq598JFi/eXEWnbNSuOaoTod8rHChIr4/UdHeeOoVZfvfV0Qi0qa8IhqlxHH+4W3o0TyNvKJSfli8EIDb3prPyzPWUFxWQVx01K4W5L/H9aVzVipz1+bw1bItNE72Ck5GciwNEmJp0yiZuJjaHYqjsKScLfnedJq3n9yDguPLaVhLU2LulJEcx6guTRjVZe/OYzFRxie/G0H2jhKy80vYuqOYLfkl9G/jjWGeX1zGhvwKVsz/iW0FJbsmmLz1hG5cPqI9W/KLueu9RRzVtQnH9cgiPiZ6r8+oTklZBR8u+IkmqW1q5OcMFyriIlLvtWmUzLRbjt51Whhg8talANw4uiv9WqezOa+4UvEpISlwinnGym3c8+GSvY751U2jaJmRxCNfLOfRL5bTINEr7qkJMTRIiOW+s/uQEh/DtOXZLP5p+65t6UlxNE9PoEV64gG1+ldu2cGvXviekrJybunnSIiNJiE2+CJXG6KijE5ZqVTXDs5Mjefvw5MYOXIk5RWObQXe952R7F1b/3HzDr5Yupk3Zq2jU5MU7jq9FwPbZAR1O9zin7ZTUlZRpzq1gYq4iMguVRXNlPgYTu/Xstr3XDqsHecObkV2fgnZO0rILSxle2EpjVO8TmRdm6ZyYu9mbC8sI6+olO1FZSzfnE9s4LrsRwt+YsLXK3c7ZnSUseTO0cREG49P+ZFZa7aRmRJPZqr3yGqQwMhKLd2PF/zE71+ZQ5QZ94/ri/20sAa+DX9FRxmNU+J3fY8Ag9s1ZMatx/D54k38+c35nP3oNLIaxPPVTUcRGx3F9qJSUqu55DF7TQ5AyC8t1DYV8WDlb4biPIhP9TuJiNSwO95e4D2f0uOg3p8UF0NSwxhaNUzaa9vILk12K7h7+tOJ3bju6E5sLyolr6iMrTtK2FZQsquzV05hCUs35jN1WTa5haUANE9L4OtbjgbgzncX8uRXK+jVIo2HftGfVg2TmFwHinh1oqOMY7tncVj7hny6cCMbcouIDXxXFz89gyU/5dEpK4UuWal0zkqlT6t0BrTJYPbqHDJT42mRHvkzl1WmIh6M2ESY8z9vgpQL3/Y7jYjUsCk/bKZzE3/+QI+JjiIjOY6Maq5d/+H4rvzh+K4AFJeVsyW/hPwir49OeYVj6rIt/OKw1vz5pO5hd/o8lBokxHJG/93PkIwb2IoF63NZsjGPjxb8xEsz1nBs9ywev2AgLRsmcXLv5hHTMTFYKuLBuPBd+OTPsLHu/nUrUh/d99ESthWUsCq7gBN6NvM7zn7Fx0Tv1pKMjjI+/O0IHxOFl7MHtQJaAd5tb1vySygsKQfg+mM7+5gsdFTEg9G0J7Q6zJsgpawYYvY/YIKIhK+dHdjWbCtg0uJNlFc4+rdJ9zuW1CAzC2pwm0inIh6sNO+vO7avg4bt/c0iIgdt2vJs/v3pUh44px//Oacfzjnyi8tIDbPRxUSCofnEg5UWuPaydqa/OUTkoJWWV3DbW/NZn1NIepJXtM1MBVwilop4sBoGxlB//TLI0ehtIpHg3o8WM29t7q7lCVNX8sOmfO44uUe96gQmdZeKeLDSW8MRv/Fe523wN4uI7JdzjvGTlnPyg18B8FNuEfd/upSjuzbhmO5ZPqcTqRkq4gei64nec0m+vzlE5IA9NHkZZRWO208+uHvBRcKROrYdiLjAAPzFKuIikWJI+4YA3DKmG6N7NKV1o70HZBGJVCriByIuMP3etpXe/OIHKKHwp4N6XzgIafb4BpDcKDTHlnrtsfMH7Jo2MzEumiM6NvY5kUjNUhE/EInp3vMnf/YeB2gIwLc1Gaj2hDR7VAxcvwhSqh+aUiRYzjnemLWOtdsKOal3s73mvhapS1TED0RiBpz/JuT9dFBvX7R4Ed26dqvZTLUkZNk3zIFvH/a+UxVxOUS5BaXc/PpcPpjv/RtdsD6XP53YvcoxzUXqAhXxA9Vh1EG/dWPOZLr1HVlzWWpRyLKnZHpFvLSg5o8t9cqq7B2c9/i3bNxexB9P6MopfVowecmmWp/TW6Q2qYiLv2IDnQVLdvibQyJes7RE+rZO5/Lh7XdNN3nO4Nb+hhIJMRVx8Vdc4DTn9nWwff2hHy8lC6I0iEd9sWl7EXd/sJjbTu5OelIc48/r73ckkVqlIi7+Skj3nt++tmaO1/9COOWBmjmW+KakrIKzHvmavKIyGqXE0btlOn8+qTsAH87/CeccRWXl/O3dRewoKeP0/i0Y3inT59QitU9FXPyV0QbGvQAFWw79WLOeh5VfHvpxxHcbcguZszaXPi3TiI4ycgtLd22758PF/LjFu/zStWkqL507hE5Z/swFLuI3FXHxX7eTauY4BVvhs79A4TbvTgKJWJvyigG4/rguHNl59xb2y1cezpb8YrYXltKnVbrGQJd6TUVc6o7m/bzn9bMP6S4C8V/nrFSeuWQwvVuk7bUtMzW+XswTLRIMFXGpO5r39Z5XfQ1Ne/+83jlf4sjBS0uM3asFLiJ7UxGXuiMxAxp2gCn3eI+AQUmtofHt0ON09VyPAGu2FvDqzLX0bJHGsZptTGSfVMSlbjnzCVj73c/LZUUw9TF47VKY9HcY/nvofTZEx/qXUao0Z00Oj3/5I+/P20CUGVce2V5FXGQ/VMSlbmnR33tUMqOkJyObbIcp98FbV8MXd8Ow30HfX0CMrq2Gg+tfns3rs9aRGh/D5cPbc9HQtjRLS/Q7lkjYUxGXus+ioMdp0P1UWPohfHEPvPs7r6gPvQ76XwCxKhi1qai0nLdmr+PUvi1IiI1meOfGdG/egHGDWpGaoLMkIsFSEZf6wwy6jIHOo2H55zDlXvjgRq+YH3Et9D0PouP2fYz4VO84clCy84t57ptVPDdtFdk7SkiOj+Gk3s05vV9Lv6OJRCQVcal/zKDj0d5j5VdeyzzY6WWH/Q6OuSPkEeuiD+Zt4Lcvz6a4rIKjuzbhsuHtGdK+od+xRCKairjUb22HeY81M2DNfiZM/+5JWDO9dnLVMc45npm2ks5Zqfx7XB86NtEIayI1QUVcBKDVIO+xLxsXwI+TayVOXWNmPHvJYWwrKCGrQYLfcUTqDE20KxKshu0gbz2UFvqdJGw453D7GUxn2aZ88opKiYuJUgEXqWFqiYsEK6Od97zlB2jaSx3cgHGPfsP89bk0bZDAjaO7MrpnUzZtL+L9eRtompbAupxy/vb8TNITY3n1V0f4HVekzlERFwlWo/be86PDoXFnGHwF9DnH67FeT81bl0u7xsm0a5xMRpJ3a9jin/K4452Fu+339EX7uVQhIgdFRVwkWM36wYn/goJsWPIBvH8DfPZX79a0QZdD445+J6xVpeUVFJaWc3yPplx3TKdd64d1bMx3fzqGn3KL+HTqDPr26c3ILk18TCpSd6mIiwQrKgoGXeq9PvJGb3jXbx+FGU/Ct49Ax2Ng8JXec1Td7G6SnV/M5CWbGdyuIQ2T4xjWsTHtM5N32ycqymicEk/jlHi2NIlRARcJIRVxkYPVcqD3OO5vMHMCfPcU/O8s79r54Mu9YV0T0/1OWWPyiko5/8npLNywHYCRXTJ5/rLDfE4lUr+piIscqtQsGHmTNxDMordh+mPw0R/h87ugzzjv2nlm130fI8w7yZWUVXD1C9+zZGMe947tzfaiMuJi6ubZBpFIoiIuUlNi4qDXWO+xfrZXzGe94LXQ96XjsfCLV8K6kBeVlVNcVsHdZ/TirIGt/I4jIgEq4iKh0LwvnPYQHPtXmP8aFG6rer/sZTDvFVjxBbQfWZsJg1ZWXkGDhFhevHwI0VHh+4eGSH2kIi4SSsmN4bArq99eWgQrp8Lku6HdkWHVGl+0YTv3fLiYHcXlPHnRQM0uJhKGQnpRy8xGm9kSM1tmZjdXsT3NzN4xszlmtsDMLg5lHpGwE5sAw6+H1dPCZkjXNVsL+N3LsznhgS+ZuWobR3VrQmJstN+xRKQKIWuJm1k0MB44FlgLzDCzt51zlUeB+DWw0Dl3spllAkvM7AXnXEmocomEnf4XwFf/9lrj7Uf62hr/etkWLnx6OlFmXDmiA786sgNpSWqBi4SrUJ5OHwwsc879CGBmLwGnApWLuANSzcyAFGArUBbCTCLhJybea42/93u4szFExUCrwdD1ZOh6Ysg/Pr+4jNXZBXRv3oD+bTK46Ii2XDqsPU3TNM65SLgLZRFvAayptLwW2POm0geBt4H1QCowzjlXEcJMIuGp3wVQnAdF270JVpZ/Bh/8AT74A/1TO0H0uV5Rz+xcox+7YssOznlsGnExUUz6/UgSYqO59cTuNfoZIhI6tr8ZiA76wGZnAcc75y4LLJ8PDHbOXVtpn7HAUOB6oAPwCdDHObd9j2NdAVwBkJmZOWDixIkhyRxq+fn5pKSk+B3joCh77UvasZbGW74hY9PXZOxYDkBBYgs2Zw5hS+Mh5KV2OqRT79uKKrjr2yKKyxzX9U+gY0bNX/eO1O8elN0vyl61UaNGzXTODdxzfShb4muByjeUtsRrcVd2MXC38/6SWGZmK4CuwPTKOznnHgMeA+jSpYsbOXJkqDKH1OTJk1H22hfJ2eGXXv5+nWDJ+yQteoc2K9+kzerXILW5d7q920nQZihEB3/tOrewlHGPTqOgPIoXrxhCn1bpIUkfyd+9svtD2Q9MKIv4DKCTmbUD1gHnAOftsc9q4GjgSzPLAroAP4Ywk0hkSmvhDeU6+HIo2ApLP4LF78Ks52HG45CQDl3GQNeToMNREJe0z8ONn7SM5ZvzeeqiQSEr4CISeiEr4s65MjO7BvgIiAaecs4tMLOrAtsfAe4EJpjZPMCAm5xzW0KVSaROSGoIfc/1HiUF3vXzxe95M6vNedHrGBcdv89D3ALclOiInngQp+Mz2sIFb0FK5kHFF5GaE9LBXpxz7wPv77HukUqv1wPHhTKDSJ0WlwTdTvYe5aWwaiqsmAJlxVXuXlBSTky0ERcdxUFdAXcVMOMJ+OBGOOvpQ4ouIodOI7aJ1BXRsd595vsYvvW2V+bw5Q+bmXLjKOJjDrIjW2JDmPQ3b4z4WrgFTkSqp2mIROqJNVsLeGPWOk7o1ezgCzjAsN9CVk9493oozKmpeCJyEFTEReqB6Su2csVzM4kOjMR2SKJj4dQHYccm+PhPNRNQRA6KirhIHTdz1VbOfnQauQUl/Pe8fjUzElvzfnDEtTDrOXj5fMhde+jHFJEDpmviImHEOcdbs9dTWl5BelIcfVqlAd50oA6IjQ7u7+7tRaXMW5vL0I6N6d86g3+c2YtT+rQgMa4GB3QZeYv3/O2jsOxTGP57r7DH7LtnvIjUHBVxkTDy9pz1/Pbl2buWH/5FfxKBaT9mc/6T00mJjyE9KdZ7JMZx85iu9GyRxrJN+Uxeson0pDhyC0t5aNIyissqmHbLUaQmxDJuUOuaDxub6M2XPvBS+PhW+PxOmP0CjL4bOh9f858nIntRERcJE4Ul5dz9wWJ6NG/Aw78YQG5hKa0aJjI7G1pmJHH9sZ3JKSglp6CEnMJSthX8PNnfnDU5/O29RbuWB7dtyJ9P6l47c4BntIFxz8Oyz+CDm+B/Z0Pn0TD6/0L/2SL1nIq4iI/u/mAxX/6wmcuHt6dTVgrlFY7bTupO60a7j7jWrnEyvzm6U7XHOb1fC47pnkVuQSnFZeV0bJKC1faUph2Phl99Dd8+DF/cA+MPo12LU+GIQRCXXLtZROoJFXERnzjneGPWWrbtKGX2mhxO69eCL286uPu3o6KMtMRY0hJ9nvs7Jg6GXge9zoZPbqPNvIlw3wcHV8QtGvqMgyNv8k7di8heVMRFfLI+t4iN24v5yyk9GDfImyvokO7fDicNmsGZjzMrui/9YpaDKz/wY+Rvhq/+DQvegJP+7Y0JLyK7UREX8cn0FdkADGiTQUJsHSnee8hN7wEjf33wB1gxBd75LTx3ute6P/7vGrNdpBLdJy7ik6O6ZDG4bUO6Nk31O0r4ajfCu84+4kavRT5+EHz/HDjndzKRsKAiLlKLNuQWcttb8ykpqyAtKZaXrxxCTJD3ftdbsQlw1K1w1VeQ2RXevgYmnARbfvA7mYjvdDpdpJa8M2c9t74xj7IKxxn9W9K3VXrt9yCPZE26wkXvw6xn4ZPb4KHDIbVZ9ft3GQMn3FN7+UR8oCIuUgven7eBa1+cRd9W6dw/ri9tG+uWq4MSFQUDLoLOY+DrB6Bga9X7bVkC3z0JI2/25l8XqaNUxEUOUFl5BeXOBd2TvLS8gns+XEzXpqm8etXhOn1eE1Kz4Pi7qt++YQ48OgIWvQMDLqy9XCK1TEVc5AA45zjtoanMX7edhslxjOySyb/O7gvAhKkriImOIqtBAlkN4slqkECj5Dg25RWTGBfDDcd1VgGvLU17Q8P2sOB1FXGp01TERQ7AtOXZzF+3ndP6Nic5PoZWDX8eWe2/ny8je0fJbvuf1LsZD57Xn/euHYYuf9ciM+hxBnz1L9ixBZIb+51IJCT2W8TNLAn4PdDaOXe5mXUCujjn3g15OhGfFZSU8cnCjbwzZz19W6WzaEMeGUmx3H1m773u7f72j0eTvaOEjdu9QVw2bi+iRYY30lhUlCp4retxOnx5n3dKfeDFfqcRCYlgWuJPAzOBwwPLa4FXABVxqbMmLd7Ea9+v5bNFmygsLadpgwSGtG/E307rydKNeVUOzvLzqfQamK9bDl1WD+857yd/c4iEUDBFvINzbpyZnQvgnCs03RcjdUx5hWP2mhwGtMkA4MXpq/lu1TbOHNCCk3s3Z1Dbhrta04e1b+RnVAnWrl9TGhhG6q5giniJmSUS+JdgZh2A4pCmEqll9328hIcnL2fKH0bRulESd53ei/SkWGLVES3yaXQ3qcOC+Q11O/Ah0MrMXgA+A24MaSqRGpRdWMHSjXnsKC6rdp/VWwto1TCRJg3iAchMjVcBrxMMtcSlLttvS9w594mZfQ8MwfsXcZ1zbkvIk4kcgpKyCqKjjOgoY9KaMn7/xRQA0pNiaZ6WSPP0RB48rx8JsdEs3ZjHum2FNEyOr7MTkdRbZmqJS50WTO/0EYGXeYHn7maGc25K6GKJHLx1OYVc87/vGdWlCb85uhPDWsRw7OAerM8pYl1OAeu2FbI5r4j4GK+l/fDk5cxek8OoLpodq+5R9x2p24K5Jv6HSq8TgMF4vdU1ua+EnRkrt3L5s99RVu64bFh7AJomRzGyb4tq3/OboztxQq9mmk2szlJLXOquYE6nn1x52cxaAZpVQMLSo1/8SExUFG9cfTjtghyfvF3j5KD3lQij0+lSxx3MiG1rgZ41HUTkQO0oLmPeulxmr8lh9uocLh/RjvziUtqrKMsu6tgmdVsw18T/y8//CqKAvsCcEGYS2Ut5haOwtJyU+BjW5RRy6YQZLN2YR0Xg/8zWDZPIzi+hdcMk4mLUq1wC1BKXOi6Ylvh3lV6XAS8656aGKI8I4BXtSYs3MXP1NmavzmHu2hzGDWrNbSd3JzMlnmZpCRzXPYu+rdPp0zKdRinerWHH9Wjqc3IJK3EpULzd7xQiIRPMNfFnaiOISGWfLPyJq57/npgoo3vzBpzRvyUjOnuTWMTFRPH0xYN9TigRIbUp5G/yO4VIyFRbxM1sHlVfTDLAOed6hyyV1HvxMdEMapvBA+f2o1laot9xJFKlZGnsdKnT9tUSP6nWUojsYVTXJozq2sTvGBLpUptC9jK/U4iETLVF3Dm3qjaDiOz04+Z8cgtL6dc6w+8oEulSmngt8fIyiD6Ym3FEwtt+u/Ga2RAzm2Fm+WZWYmblZqaeIhISW/KLuejpGVzzv1mUlFX4HUciXevDoaIU5r/mdxKRkAjmXpwHgXOBH4BE4DLgv6EMJfXTwvXbOfvRaWzKK+LB8/rpVjE5dJ2OhyY94Mv7oKLc7zQiNS6o35LOuWVAtHOu3Dn3NDAqtLGkvpi5aiu5BaU8PXUFp42fSn5RGRMuHqxT6VIzoqJgxA2wZSksfMvvNCI1LpiLRAVmFgfMNrN7gA2AhsOSQ7Zow3YufGoGR3bJJD0xluGdGnPvWX1omBzndzSpS7qfCo07w5T7oPtpXmEXqSOCKeLn47XYrwF+B7QCzgxlKKnbNucVM2dNDn9+az4p8TH8+cTuNEyOIzbaMNOsU1LDoqJh+O/hjSvhyWMhNnDLYmwiHPtXaNLN33wihyCYIt4feN85tx34S4jzSB2TV1TKvHW5pCXG0qN5Gquyd3DkvZMBaJAQw4tXDKFpWoK/IaXu6zkWln8OuWvBBTpMrvkW3rwaLvtMrXOJWMEU8VOA+81sCvAS8JFzriy0sSRSOed47ptVzF6Tw9y1uSzfnI9zMG5gK/4xtjetMpK47aTu9GyRRs8WDUiK020/UguiY+CMx3ZfN+dleOMKmPUcDLjQn1wihyiYYVcvNrNYYAxwHvCQmX3inLss5Okk4pgZT321gh0l5fRpmcYpfZrTu2UafVqmAxAVZVwyrJ2/IUUAep8NM5+GT++AbidDUkO/E4kcsKCaQc65UjP7AG8Y1kTgVLxbzUR2WZ9TSEpCDG9dM4wGCTG6vi3hzQxOuBceHQGT/g4n3ud3IpEDFsxgL6PNbAKwDBgLPAE0C3EuiTBFpeWc8uBX3PH2AtISY1XAJTI07QWDLoPvnoTnz4SFb/udSOSABNOb4yLgTaCzc+5C59z7uiYulRWUlHHpMzPI3lHCcd01FahEmFG3eqfTs5fBxPO9VnmFRguUyBDMNfFzaiOIRKYNuYVc9+Jsvlu1lX+e1YfRPVXEJcIkpsPZz0JZMbx3PXzxD9i4gOjGv/Q7mch+qWuwHJI/vTGf2WtyuP+cfpzSp7nfcUQOXkw8nPIgZPWCj26h35p5MKAbZLT1O5lItVTE5YBszivmzVnrGNOrKS0zkvjTSd2JiTJaNUzyO5rIoTODIVdBZmfiXzwfHhsFZz8D7Ub4nUykSirisk/lFY6Zq7bx6tIS7pv3JfPXeRPYVTjHlUd2oF1jjcArdVCHo/i+/70c9uP98OxpMO456Hqi36lE9lJtETezeXi3lO21CXDOud4hSyW+2pRXxPqcIvq2Sqe8wnHx09MpLC1nYJtU/nB8F47snEnPFml+xxQJqcKk5nDZp/BAP2/yFBVxCUP7aomfVGspJGws3ZjH2Ie/pnl6Ih/+dgRxMVE8e+lgflo6hxOPPdzveCK1K6EBxKeCq6o9I+K/aou4c25VbQYR//2UW8SFT00nITaa+87qs2v9gDYNmbxC931LPWX283jrImFmX6fT89j36fQGIUslte771dv47UuzySsqY+KVh9O9uf7zigBgUVT9q1DEf9UO9uKcS3XONajikRpsAQ+M9rbEzJaZ2c3V7DPSzGab2QIz++JgfxA5NC9NX015heOZSwargIvsRi1xCV9B9043sybArjkjnXOr97N/NDAeOBZYC8wws7edcwsr7ZMOPASMds6tDnyG1CLnHGbGbSf3oMI5GiTE+h1JJLzEJkBJgd8pRKoUzNjpp5jZD8AK4AtgJfBBEMceDCxzzv3onCvBm8b01D32OQ94fecfBM65TQeQXQ7RquwdHPvvKcxavY2U+BgVcJGqJDWGwq1+pxCpkrn99Lo0sznAUcCnzrl+ZjYKONc5d8V+3jcWr4V9WWD5fOAw59w1lfa5H4gFegCpwH+cc89WcawrgCsAMjMzB0ycODH4nzCM5Ofnk5KS4neMXZ5bWMzkNWX888hE0hP2/fdcuGU/EJGcHSI7f13I3m3hP0nN+4Hphz3id6Sg1YXvPRKFMvuoUaNmOucG7rk+mNPppc65bDOLMrMo59wkM/tHEO+rqjvznn8xxAADgKPxpjidZmbfOOeW7vYm5x4DHgPo0qWLGzlyZBAfH34mT55MuGTfuqOEqZ99xhn9W3La6D773T+csh+oSM4OkZ2/TmQveB/mzImon6NOfO8RyI/swRTxHDNLAaYAL5jZJiCYWczWAq0qLbcE1lexzxbn3A5gh5lNAfoAS5GQev6bVRSVVnD5iPZ+RxEJb8mNoTgXSnZAnEYolPASzFSkpwIFwO+AD4HlwMlBvG8G0MnM2plZHHAOsOdkvW8Bw80sxsySgMOARcGGl4NTVFrOM1+vZFSXTDpnpfodRyS8tR4CGLx6KZSX+p1GZDfBtMSbABucc0XAM2aWCGQB2ft6k3OuzMyuAT4CooGnnHMLzOyqwPZHnHOLzOxDYC5QATzhnJt/CD+PBCE2Ooq/ntqTFhmJfkcRCX/tRsCJ//SmKX3jKjjjMYiK9juVCBBcEX8FOKLScnlg3aD9vdE59z7w/h7rHtlj+V7g3iBySA2JjjJO7N3M7xgikWPQpVC8HT69A+JT4KT7vZHcRHwWzOn0mMAtYgAEXseFLpKEknOOp6euYM1W3fcqckCG/c57zJwAn9ym8dQlLARTxDeb2Sk7F8zsVGBL6CJJKC1Yv52/vLOQL3/Qf0KRA3b07TDoMvj6AZh8twq5+C6Y0+lX4fVKH493i9ha4IKQppIa55zjnbkb+MvbC0iMjeb4Hll+RxKJPGYw5l4oLYQv7obcNd6p9RidnBR/7LeIO+eWA0MCt5mZcy4v9LGkJhWXlXPVczOZtGQzfVqmcfeZvWmUEu93LJHIFBUFp46H9NYw+f9g20o4+zlIbuR3MqmHghl2NcvMngRecc7lmVl3M7u0FrLJISgsKWf6Cm+oyPiYaErLHX8+qTuvXz2Ubs00wYnIITGDkTfDmU/C2u/giaNhs4a3kNoXzOn0CcDTwK2B5aXAy8CTIcokByGvqJR563KZtzaXeetymbJ0M8VlFXz7x6NJT4rjuUsHY+pNK1Kzeo31WuQvnQdPHANnPwMdRvmdSuqRYDq2NXbOTcS7jxvnXBnebWbik9zCUr5etoVHv1jO5rxiAF6esYbzHv+W//tgMbNW53BU1yY8e8lg0hK9SU1UwEVCpNVguPxzSGsBz58J08ZDhX5FSu0IpiW+w8waERj33MyGALkhTSXVWrA+l1MfnEpZhdcrtnPTVEZ1acLonk3plJVKrxZpNExWJxuRWpXeGi75CN64Ej76I8x7BU76NzTv53cyqeOCKeLX4w2X2sHMpgKZwNiQppJqrdiyg7IKx71je3NMtywyAgW7ZUYSLTOSfE4nUo8lNIBz/gcLXocPb4HHj/JuRzvqT5CQ5nc6qaP2ezrdOfc9cCTeqG1X8vO0oeKD5Zt2AHBU1ya7CriIhAkz6HkmXDMDBl0O0x+HBwfB/Nd0T7mERLVF3MyizexcM7sB6OKcWwC0Bb4AHqylfBJQVOpdYzuxd1P+ckoP3SImEs4S0uCEe7xr5anN4NVL4LnTIXu538mkjtnX6fQn8aYSnQ7818xWAUOAW5xzb9ZCtnovr6iUzxdv4qMFPzF5yWbe+81wOjZJpWMTnQgRiQgt+nuF/Lun4LO/wkOHw/DrYehvITbB73RSB+yriA8EejvnKswsAW+o1Y7OuZ9qJ1r9tjmvmOPvn8LWHSVkpsZzRv8WxESph7lIxImKhsGXQ7eTvU5vk/8P5k70ZkbT7WhyiPZVxEuccztvKysys6Uq4LXnw/kb2LqjhCcuGMhRXZsQpQIuEtlSm8LYp6DfL+G938Nzp0HPsXD83yFVwyDLwdlXx7auZjY38JhXaXmemc2trYD1Vf82GVw2rB3HdM9SARepSzocBb+aBiNvgUVvex3fpj+ue8vloOyrJd6t1lIIhSXlzF+fy6zV22iVkcSYXs3o0Vy3pYjUSbEJ3rCtvc7yWuXv3wCzX9C95XLAqi3izrlVtRmkvrrrvYVM+zGbxRvydg3gctaAlozp1cznZCISco06wPlveLegffRH797ywVfCcX+D6GCG8ZD6Tv+X+GzZpnzSEmO58sj29GuVQd/W6TTW7WMi9YeZNwZ7p2O9HuzfPgyF2+C0h70Z00T2QUW8FpVVOGavyWHmqm1UVDguOKINT1882O9YIhIOEtK8HuspTWHS37zlMf/wirxINVTEa8HMVdv4xweLmbW6gNKPpwLQMiORwtJyfnN0J5/TiUhYGXEDFOXAtAe9Qn7Urft9i9Rf1RbxQI/0ascJdM71DkmiOigxNpqS8gqOahXDacN6079NBlkNNNCDiFTBzLsmXpQLU+7xxmQ/4lq/U0mY2ldL/KTA868Dz88Fnn8BFIQsUR3hnOPZaato1TCRo7pm8eavhzJ58mRGqsOaiOyPGZz8HyjOg4//BHHJMPASv1NJGKq214RzblWgh/pQ59yNzrl5gcfNwPG1FzHylJZX8LuXZ3P72wv48octfscRkUgUFQ1nPA4dj4V3fwcf/hHKy/xOJWEmmK6PyWY2bOeCmR0BJIcuUuR7/MsfeXP2ev5wfBduO6m733FEJFLFxMG5L8JhV8E34+H5M6Bgq9+pJIwEU8QvBcab2UozWwk8BOi8TjV2FJfxwGc/cHyPLH49qiOmnqUiciiiY71e6qeOh9XT4LGRsHGB36kkTAQzn/hM51wfoDfQxznXNzDHuFQhv7iMotIKjuzcxO8oIlKX9PslXPQ+lBXDE8fCwrf8TiRhYL+3mJlZPHAm3lziMTtbls65v4Y0WYRqmBzHJ78bQZNU9T4XkRrWahBc+QW8/EuYeAGM/COMvMnvVOKjYE6nvwWcCpQBOyo9pAolZRV0ykolLSnW7ygiUhelNoWL3oOeZ8Lkv0POGr8TiY+CKeItnXPjnHP3OOf+ufMR8mQRaP66XEbcM4mF67f7HUVE6rKYeDgy0AL/4WN/s4ivginiX5tZr5AnqQNenbmWnMJSmqXpVLqIhFjjzpDeRkW8ngumiA8DZprZEs0nXrXS8gpufm0uE75eyQm9mpGRHOd3JBGp68yg8/Hw4xdQWuh3GvFJMGOnjwl5igg3eclmXpqxhsuHt+Om0V39jiMi9UWn42H6Y96obmktd61utfpH+GpW9e/L6unNmiYRb79FfOe84mbWBNB54iokxEbRv3U6Fx7RlphoTR0oIrWk7TBIbQ4znthtdQeAH/fz3iFXw7F3at7yCBfMLWanAP8EmgObgDbAIqBHaKNFjuGdMhneKdPvGCJS38QmwO/mQ3nJbqunTJnCiBEjqn5PRTl8fid88xD8NA/OmgDJjUOfVUIimGbjncAQYKlzrh1wNDA1pKkiyJqtBcxbm+t3DBGpr6KiITZxt0dFdPxe63Y94lO8EeBOexjWTPdGgFs/2++fQg5SMEW81DmXDUSZWZRzbhLQN7SxwptzjpdnrObMh79m+D2TOOPhqbw1e53fsUREgtf3PLjkQ3AV8NTxMHei34nkIARzMSTHzFKAKcALZrYJb+CXemtdTiE3vTaP9o2TuXF0F07p05yWGUl+xxIROTAt+sMVX8ArF8Lrl8NPc73r5JrzIWIE0xI/FW/+8N8BHwLLgZNDGSrcbS/0/oa5cXQXrh7ZUQVcRCJXSiZc8JY3NvvX/4XNS/xOJAcgmN7pO4dYrQCeCW2c8PXj5nzKKhyNU+Jp3SiJ5y4dTNemDfyOJSJy6KJjvd7qs56HjfOhiW6VjRS6tyBId767kElLNgMw6YaR6o0uInVLo04QFesV8V5j/U4jQdJNzUG6aGi7Xa9vfHWOj0lEREIgJg4yu2iu8gijIh6EJ778kc5ZKTx90SDGDWzFHafoFnkRqYOadFcRjzDBDPYyFLgDb5CXGMAA55xrH9po/isrr+CZaav423uL+Nt7i1h594mM6trE71giIqGR1QPmTYTCbZCY4XcaCUIw18SfxOuZPhMoD22c8FJW4bjz3YUAHN6+kc9pRERCLKun97xxIbQd6m8WCUowp9NznXMfOOc2Oeeydz5CniwMJMRGM/mGkQCM6dXU3zAiIqGWFbhUqFPqESOYlvgkM7sXeB0o3rnSOfd9yFKFgRkrt7Ilr5jRPZuy7K4xmthEROq+1KbeafSN8/1OIkEKpogfFngeWGmdA46q+Tjh47lpq5i5ahtjejUjJlqjF4lIPWDmnVJXSzxiBDPYy6jaCBIuSssreGfOeiYt3sRR3dSJTUTqmZYDYep/YMWX0G6432lkP/Z7jtjM0szsX2b2XeDxTzNLq41wta2iwnHCf77k+olzaJ6eyDWjOvodSUSkdg3/PTTqCK9eDNvX+51G9iOYC71PAXnA2YHHduDpUIbyS0l5BeUVjuuO7sSHvx1Op6xUvyOJiNSu+FQY9zyUFMDEC6GsZP/vEd8Ec028g3PuzErLfzGz2SHK46uE2Gg+D/RGFxGptzK7wKkPeq3xj/8EJ9zjdyKpRjAt8UIzG7ZzITD4S2HoIomIiO96ngFDfg3TH4U5L/mdRqoRTBH/FTDezFaa2SrgQeCqYA5uZqPNbImZLTOzm/ex3yAzKzczX0fdz84v5uxHpvH54o1+xhARCQ/H/gXaDIU3roLJd0NFvRrvKyLst4g752Y75/oAvYFezrl+zrn9zgBiZtHAeGAM0B0418y6V7PfP4CPDjR8TSsoKWf6yq1k5+sakIgI0bHwi1egzzkw+f/gudMhf5PfqaSSaq+Jm9kvnXPPm9n1e6wHwDn3r/0cezCwzDn3Y+B9LwGnAgv32O9a4DVg0IFFr3ml5RUAxGpgFxERT1wynPYwtB0G790AjwyDM5+AdiP8TiaAOeeq3mB2pXPuUTO7vartzrm/7PPA3qnx0c65ywLL5wOHOeeuqbRPC+B/eAPHPAm865x7tYpjXQFcAZCZmTlg4sSJwfxsB2xdXgW3Ti3k6j7xDG5W81Ot5+fnk5KSUuPHrQ3K7p9Izq/s/ghV9uT8VXRfeA9JBetZ2XYcq9qcBRZdo5+h771qo0aNmumcG7jXBudcSB7AWcATlZbPB/67xz6vAEMCrycAY/d33M6dO7tQmb8ux7W56V33wbwNITn+pEmTQnLc2qDs/onk/Mruj5BmL8pz7rXLnbu9gXMTTnYuf3ONHl7fe9WA71wVNTGYwV7uMbMGZhZrZp+Z2RYz+2UQfzisBVpVWm4J7DlywEDgJTNbCYwFHjKz04I4do3Lzi8mLjqKni0akJEU60cEEZHwF58Cpz8KpzwIq7+Bj//sd6J6LZiLv8c557YDJ+EV5s7AH4J43wygk5m1M7M44Bzg7co7OOfaOefaOufaAq8CVzvn3jyA/Ifss0UbOf2hqQz426dM+WEL7147nMM07aiISPXMoP/50O8XsOB1b/5x8UUwRXxns/QE4EXn3NZgDuycKwOuwet1vgiY6JxbYGZXmVlQt6jVhkuf+Y5Zq3No2yiJacu3+B1HRCRyDLgYyop0H7mPgum99Y6ZLcYb4OVqM8sEioI5uHPufeD9PdY9Us2+FwVzzJo2dkBLOjVJ4fgeTfnmx3oxTbqISM1o1htaDIDvnobDrvJa6FKrgpnF7GYz+wew3TlXbmY78G4VqxPuO6vPrtdtGyf7mEREJAINuBjevgZWT4M2R/idpt6p9nS6mR0VeD4DGAWcGng9GtB/KRER8YZnjW/gtcal1u2rJX4k8DlwchXbHPB6SBKJiEjkiEuG3uPg+2dhzD8gqaHfieqVaou4c+72wPPFtRdHREQizsCLYcbjMPt/cMQ1+99fakww94n/3czSKy1nmNnfQppKREQiR1YPaDkYZk6AakYBldAI5hazMc65nJ0LzrlteLebiYiIeAZeDNk/wMqv/E5SrwRTxKPNLH7ngpklAvH72F9EROqbHqdDXCrMf83vJPVKMPeJPw98ZmZP43VouwR4JqSpREQkssQmQssBsP57v5PUK8HcJ36Pmc0FjgEMuNM55/vc3yIiEmaa9YVp46GsGGJ0wrY2BDvf5iKgzDn3qZklmVmqcy4vlMFERCTCNO8HFaWwcQG06O93mnohmN7pl+NNTvJoYFUL4M0QZhIRkUjUvJ/3vH6WvznqkWA6tv0aGApsB3DO/QA0CWUoERGJQOmtIbkJzJ0IFeV+p6kXginixc65kp0LZhaD18FNRETkZ2Zw7F9gzTfw9QN+p6kXginiX5jZH4FEMzsWeAV4J7SxREQkIvU5F7qdAp/fBRvm+J2mzgumiN8EbAbmAVfiTS36p1CGEhGRCGUGJ/8HkhrB61dAaaHfieq0fRZxM4sC5jnnHnfOneWcGxt4rdPpIiJStaSGcNp42LwYPr3D7zR12j6LuHOuAphjZq1rKY+IiNQFHY+BwVfCt4/A/8bBlh/8TlQnBXOfeDNggZlNB3bsXOmcOyVkqUREJPIdfxektYAv7oWHhsDgK+DIGyExw+9kdUYwRfwvIU8hIiJ1T3QsDL3O6+w26S6vVT7nRRh1Kwy4GKKDHW9MqlPt6XQzSzCz3wJnAV2Bqc65L3Y+aiugiIhEuJQmXme3K6dAVk94/wZ4ZCgs+9TvZBFvX9fEnwEG4vVKHwP8s1YSiYhI3dS0F1z4DpzzP2989efPhBfOgs1L/U4WsfZ1LqO7c64XgJk9CUyvnUgiIlJnmUHXE72Ob9Mfgy/u8a6X9/sFHHmz3+kizr5a4qU7Xzjnymohi4iI1Bcx8XDEtfCbWV6HtzkvwQP96LDsaSjY6ne6iLGvIt7HzLYHHnlA752vzWx7bQUUEZE6LLkxjLkbrp0JvcbScu3b8J8+Xgu9ON/vdGGv2tPpzrno2gwiIiL1WHprOO0hZsQOYXDeR15v9umPwYg/wICLND95NYIZdlVERKRWFCS3hnNegMs+g8yu8MGN8N+BMPt/UFHhd7ywoyIuIiLhp+VAryf7+W94w7i++Sv4UjdJ7UlFXEREwpMZdDgKrpgM3U+DL++DbSt9DhVeVMRFRCS8mcHo/wOLhg90G1plKuIiIhL+GjSHkTfD0g9gyQd+pwkbKuIiIhIZhvzq585umqccUBEXEZFIER0LJ9wHOath5jN+pwkLKuIiIhI52g33WuNL3vc7SVhQERcRkcjS6ThY9TUU5/mdxHcq4iIiElk6Hw8VpbB8kt9JfKciLiIikaXVYRCfBj985HcS36mIi4hIZImOhY5Hw6J3YOsKv9P4SkVcREQiz6hbAYMXz4GiXL/T+EZFXEREIk/jjnD2s5C9DF65GMrL/E7kCxVxERGJTO2PhBP/Bcs/g49u8TuNL6qdT1xERCTsDbgQtiyFaQ9Co05w2BV+J6pVKuIiIhLZjv0rZC+HD2+CvA3eGOsx8X6nqhU6nS4iIpEtKhrGPgl9zoOv/gWPjYINc/xOVStUxEVEJPLFJcNp4+Hcl6FgCzx+FEy+G8pL/U4WUiriIiJSd3QZDVd/Az1Oh8n/B08cDZsW+Z0qZFTERUSkbklqCGc+AWc/B7nr4NER8NW/IX8z7Njy86O0yO+kh0wd20REpG7qfgq0Phzeux4+vcN7VNagJfxuPpj5ka5GqIiLiEjdlZLpDQqz7DPYVmmI1uWTYMl7UFYEsYn+5TtEKuIiIlK3mUGnY/Zet+Q9KNoe0UVc18RFRKT+iU/znou3+5vjEKmIi4hI/ZPQwHuO8MlTVMRFRKT+Sczwnrf84G+OQxTSIm5mo81siZktM7Obq9j+CzObG3h8bWZ9QplHREQEgOb9IKsXfHo7FGz1O81BC1kRN7NoYDwwBugOnGtm3ffYbQVwpHOuN3An8Fio8oiIiOwSHQunPQQF2fBh5M6AFsqW+GBgmXPuR+dcCfAScGrlHZxzXzvntgUWvwFahjCPiIjIz5r1huG/h7kvwZIP/E5zUEJZxFsAayotrw2sq86lQGR+iyIiEpmG3wBNesA7v4XCbfvdPdyYcy40BzY7CzjeOXdZYPl8YLBz7toq9h0FPAQMc85lV7H9CuAKgMzMzAETJ04MSeZQy8/PJyUlxe8YB0XZ/RPJ+ZXdH8p+YFLyljNg5g2sbXkSyzteetDHCWX2UaNGzXTODdxrg3MuJA/gcOCjSsu3ALdUsV9vYDnQOZjjdu7c2UWqSZMm+R3hoCm7fyI5v7L7Q9kPwgvjnLu/zyEdIpTZge9cFTUxlKfTZwCdzKydmcUB5wBvV97BzFoDrwPnO+eWhjCLiIhI9Toc5Q3LuvVHv5MckJANu+qcKzOza4CPgGjgKefcAjO7KrD9EeA2oBHwkHkD0Je5qk4XiIiIhFKHo7zn5ZOgYXt/sxyAkI6d7px7H3h/j3WPVHp9GXBZKDOIiIjsV6MOkNYKln8Ogw7+unht04htIiIiZtBhFKz4Eioq/E4TNBVxERERgFZDoDgXspf5nSRoKuIiIiIAzQIjf2+Y42+OA6AiLiIiApDZFWISYMNsv5METUVcREQEIDoGsnqqJS4iIhKRmveFtd9FzFjqKuIiIiI7Hf5r7z7xF8+B1y6DHXuNBB5WVMRFRER2atgerpgMI2+BBW/C+MEw/3UI0Twjh0pFXEREpLKYOBh5M1z5BaS3glcvhpd/CXk/+Z1sLyriIiIiVcnqAZd+Csf+FZZ96rXKZ70QVq1yFXEREZHqRMfA0OvgqqnQpDu8dTV8cY/fqXZRERcREdmfxh3hove9W9DWTvc7zS4q4iIiIsGIioKULCjc5neSXVTERUREgpWYoSIuIiISkVTERUREIlRiBhTmhM10pSriIiIiwYqJAxxUlPmdBFARFxEROQAWeA6Pe8VVxEVERIJlgSIeJgO+qIiLiIgETS1xERGRyKSWuIiISISKS/GeS/L9zRGgIi4iIhKspIbec0F4zDMe43eAmlBaWsratWspKiryO8o+paWlsWjRIr9j7CUhIYGWLVsSGxvrdxQRkfCW1Mh7VhGvOWvXriU1NZW2bdtiO69XhKG8vDxSU1P9jrEb5xzZ2dmsXbuWdu3a+R1HRCS87SriW/3NEVAnTqcXFRXRqFGjsC7g4crMaNSoUdifxRARCQuJ4XU6vU4UcUAF/BDouxMRCVJsovdcFh4NnzpTxOui7777jt/85jfVbl+/fj1jx46txUQiIvVcVOAqdJgMu1onrolHivLy8gPaf+DAgQwcOLDa7c2bN+fVV1891FgiIhKsXUX8wH6fh4pa4jVk5cqVdO3alQsvvJDevXszduxYCgoKaNu2LX/9618ZNmwYb7zxBh9//DGHH344/fv356yzziI/37vXcMaMGRxxxBH06dOHwYMHk5eXx+TJkznppJMA+OKLL+jbty99+/alX79+5OXlsXLlSnr27Al4/QIuvvhievXqRb9+/Zg0aRIAEyZM4IwzzmD06NF06tSJG2+80Z8vSESkLoiK9p7VEg+dcY9O22vdSb2bcf7hbSksKeeip6fvtX3sgJacNbAVW3eU8KvnZ+627eUrDw/qc5csWcKTTz7J0KFDueSSS3jooYcA7xaur776ipUrV3LBBRfw6aefkpyczD/+8Q/+9a9/cfPNNzNu3DhefvllBg0axPbt20lMTNzt2Pfddx/jx49n6NCh5Ofnk5CQsNv28ePHAzBv3jwWL17Mcccdx9KlSwGYPXs2s2bNIj4+ni5dunDttdfSqlWroH4mERGpRC3xuqtVq1YMHToUgF/+8pd89dVXAIwbNw6A6dOns3DhQoYOHUrfvn155plnWLVqFUuWLKFZs2YMGjQIgAYNGhATs/vfV0OHDuX666/ngQceICcnZ6/tX331Feeffz4AXbt2pU2bNruK+NFHH01aWhoJCQl0796dVatWhe5LEBGpy6KiISEddmzyOwlQR1vi+2o5J8ZF73N7w+S4oFvee9qzl/fO5eTk5F3rjj32WF588cXd9ps7d+5+e4jffPPNnHjiibz//vsMGTKETz/9dLfWuNvHOL7x8fG7XkdHR1NWFh6ngUREIlJGW9i6wu8UgFriNWr16tVMm+adyn/xxRcZNmzYbtsHDRrE1KlTWbZsGQAFBQUsXbqUrl27sn79embMmAF4g8LsWWiXL19Or169uOmmmxg4cCCLFy/ebfuIESN44YUXAFi6dCmrV6+mS5cuIfk5RUTqtYy2sG2l3ykAFfEa1a1bN5555hl69+7N1q1b+dWvfrXb9saNGzNhwgTOPfdcevfuzZAhQ1i8eDFxcXG8/PLLXHvttfTp04djjz12r8FX7r//fnr27EmfPn1ITExkzJgxu22/+uqrKS8vp1evXowbN44JEybs1gIXEZEa0rAd5KwOi+vidfJ0ul+ioqJ45JFHdlu3cuXK3ZaPOuqoXS3uygYNGsQ333yz27qRI0cycuRIAP773//u9Z62bdsyf/58wOs8N2HChL32ueiii7jooot2Lb/77rtB/CQiIlKtjLZQUQrb10F6a1+jqCUuIiJyIDIC80yEwSl1FfEaUrlVLCIidVhGW+85DDq3qYiLiIgciLSW3v3iaomLiIhEmKho71q4iriIiEgEymgLG2ZDcZ6vMVTERUREDlS/82HbKnjiGMhe7lsMFfEwNmHCBK655hoA7rjjDu677z6fE4mICAA9z4AL3oT8TfD4KPjhU19iqIiHgHOOiooKv2OIiEgotRsBV0z2ro+/MJZWq1+DfQyBHQoq4jVk5cqVdOvWjauvvpr+/ftz5513MmjQIHr37s3tt9++a79nn32W3r1706dPn10Tlrzzzjscdthh9OvXj2OOOYaNGzf69WOIiMiByGgDl3wMPU6nw4/PwmuXQklBrX183Rux7YOb4ad5NXvMpr1gzN373W3JkiU8/fTTnHbaabz66qtMnz4d5xynnHIKU6ZMISEhgbvuuoupU6fSuHFjtm7dCsCwYcP45ptvMDOeeOIJ7rnnHv75z3/W7M8gIiKhEZcEY59ieWEqHeY/C1uWwnkToUHzkH903SviPmrTpg1Dhgzhhhtu4OOPP6Zfv34A5Ofn88MPP7B161bGjh1L48aNAWjYsCEAa9euZdy4cWzYsIGSkhLatWvn288gIiIHwYw1rc+gw+GnwFf/gvgGtfKxda+IB9FiDpWdU44657jlllu48sord9t+zz33VDnl6LXXXsv111/PKaecwuTJk7njjjtqI66IiNS0TsdAx6NhP9NL1xRdEw+B448/nqeeeor8/HwA1q1bx6ZNmxg5ciQTJ04kOzsbYNfp9NzcXFq0aAHAM888409oERGpGbVUwKEutsTDwHHHHceiRYs4/PDDAUhJSeH555+nW7du3HrrrRx55JFER0fTr18/JkyYwB133MFZZ51FixYtGDJkCCtW+D8er4iIhD8V8Rqy5wQo1113Hdddd91u++Tl5XHhhRdy4YUX7rb+1FNP5dRTT93rmJWnEdUpdhER2ZNOp4uIiEQoFXEREZEIFdIibmajzWyJmS0zs5ur2G5m9kBg+1wz6x/KPCIiInVJyIq4mUUD44ExQHfgXDPrvsduY4BOgccVwMMH+3muloe6q0v03YmIRKZQtsQHA8uccz8650qAl4A9e2+dCjzrPN8A6WbW7EA/KCEhgezsbBWjg+CcIzs7m4SEBL+jiIjIAbJQFT4zGwuMds5dFlg+HzjMOXdNpX3eBe52zn0VWP4MuMk5990ex7oCr6VOZmbmgIkTJ+75WSQnJxMdHR2Sn6WmOOeqHOzFb+Xl5ezYsWOffwTl5+eTkpJSi6lqTiRnh8jOr+z+UHZ/hDL7qFGjZjrnBu65PpS3mFVVrfasEsHsg3PuMeAxgC5duriRI0cecjg/TJ48GWWvfZGcHSI7v7L7Q9n94Uf2UJ5OXwu0qrTcElh/EPuIiIhIFUJZxGcAncysnZnFAecAb++xz9vABYFe6kOAXOfchhBmEhERqTNCdjrdOVdmZtcAHwHRwFPOuQVmdlVg+yPA+8AJwDKgALg4VHlERETqmpB1bAsVM8sDlvid4yA1Brb4HeIgKbt/Ijm/svtD2f0RyuxtnHOZe66MxLHTl1TVQy8SmNl3yl77Ijk7RHZ+ZfeHsvvDj+wadlVERCRCqYiLiIhEqEgs4o/5HeAQKLs/Ijk7RHZ+ZfeHsvuj1rNHXMc2ERER8URiS1xEREQIsyJ+KFOXmlm6mb1qZovNbJGZHR5m2bua2TQzKzazG/bYFu7ZfxH4vuea2ddm1ieCsp8ayD3bzL4zs2GRkr3SfoPMrDwwH8HOdWGd3cxGmllu4HufbWa3RUr2wD4jA7kXmNkXldaHdXYz+0Ol73x+4P+bhhGSPc3M3jGzOYHv/eJK28I9e4aZvRH4XTPdzHrWWnbnXFg88AaEWQ60B+KAOUD3PfY5AfgAb8z1IcC3lbY9A1wWeB0HpIdZ9ibAIOAu4IY9toV79iOAjMDrMRH2vafw82Wj3sDiSMleab/P8QZGGhsp2YGRwLvVvD/cs6cDC4HWgeUmkZJ9j/1PBj6PlOzAH4F/BF5nAluBuAjJfi9we+B1V+Cz2vrew6klftBTl5pZA2AE8CSAc67EOZcTTtmdc5ucczOA0srrIyT71865bYHFb/DGuI+U7Pku8K8HSCYwwU4kZA+4FngN2LRzRQRl30uEZD8PeN05tzqQcRNETPbKzgVehIjJ7oBUMzO8P763AmURkr078Fkg32KgrZll1Ub2cCriLYA1lZbXBtYFs097YDPwtJnNMrMnzCw5lGGDzBWMSMt+Kd7ZEIiQ7GZ2upktBt4DLgmsDvvsZtYCOB14ZI/3hn32gMMDp0Y/MLMegXWRkL0zkGFmk81sppldEFgfCdkBMLMkYDTeH4AQGdkfBLrhTYI1D7jOOVdBZGSfA5wBYGaDgTZ4jZ2QZw+nIn4oU5fGAP2Bh51z/YAdQLXXGEMgqClVqxEx2c1sFF4RvymwKiKyO+fecM51BU4D7gysjoTs9wM3OefK91gfCdm/xxsmsg/wX+DNwPpIyB4DDABOBI4H/mxmnYmM7DudDEx1zm0NLEdC9uOB2UBzoC/wYKAlGwnZ78b7w2823tmzWUAZtZA9nIr4oUxduhZY65z7NrD+VbwvrrYcypSqEZHdzHoDTwCnOueyK7037LPv5JybAnQws8ZERvaBwEtmthIYCzxkZqcRAdmdc9udc/mB1+8DsRH0va8FPnTO7XDObQGmAH2IjOw7nUPgVHql94Z79ovxLmM459wyYAXe9eWwzx74//1i51xf4AK8a/orqIXs4VTED3rqUufcT8AaM+sS2O9ovI4ptSWY7FWKhOxm1hp4HTjfObd05/oIyd4xcI0N8+5miAOyIyG7c66dc66tc64t3j/+q51zb0ZCdjNrWul7H4z3uyYivnfgLWC4mcUETksfBiyKkOyYWRpwJN7PAUTGv1VgdSAXZpYFdAF+jITs5vVAjwssXgZMCRT20Gc/kF5woX7g9T5fitcT8NbAuquAqwKvDRgf2D4PGFjpvX2B74C5eKfuMsIse1O8v8q2AzmB1w0iJPsTwDa8U12zge8i6Hu/CVgQyD0NGBYp2ffYdwK7904P6+zANYHvfQ5eZ8gjIiV7YPkPeL9s5wO/jbDsFwEvVfHesM6Odxr9Y7zf7fOBX0ZQ9sOBH4DFeA2ejNrKrhHbREREIlQ4nU4XERGRA6AiLiIiEqFUxEVERCKUiriIiEiEUhEXERGJUCriImHCzBrZzzNQ/WRm6wKvc8ysxu+LNbM7bI8Z9YJ4T3416ydYpVnWDiFTjRxHpL5QERcJE865bOdcX+eN+vQI8O/A675Axf7eb2YxIQ0oImFHRVwkMkSb2ePmzbP8sZklAgQm6fi7eXNeX2dmA8zsi8DEHR+ZWbPAfr8xs4XmzXf8UqXjdg8c40cz+83OlWZ2vXnzUc83s9/uGSYwauKDgWO+hzfV7p77dDOz6ZWW25rZ3MDr28xsRuD4j+0c3W2P968MDNWKmQ00s8mB18lm9lTg/bPMLKgZ1ETqIhVxkcjQCRjvnOuBN+LfmZW2pTvnjgQewJtsZKxzbgDwFN789eBNutDPOdcbb6SpnbriTTwxGLjdzGLNbADeONaHAUOAy82s3x55TscbFrMXcDnenPO7cc4tAuLMrH1g1ThgYuD1g865Qc65nkAicNIBfBe34s2TPQgYBdxrtTurlUjYUBEXiQwrnHOzA69nAm0rbXs58NwF6Al8Yt5sSn8iMPc73pCPL5jZL/FmV9rpPedcsfMm+tgEZAHDgDecNwFIPt4wksP3yDMCeNE5V+6cWw98Xk3uicDZgdfjKmUdZWbfmtk84CigR1VvrsZxwM2Bn3EykAC0PoD3i9QZuoYmEhmKK70ux2u97rQj8GzAAufc4VW8/0S8wnsK3tSaO4vmnseNoeqpF6sSzJjNLwOvmNnrgHPO/WBmCcBDeHMfrDGzO/AK8Z7K+LmhUXm7AWc655YEmVOkzlJLXKTuWAJkmtnhAIFT4z3MLApo5ZybBNwIpAMp+zjOFOA0M0sKnKY+Hfiyin3OMbPowHX3UVUdyDm3HO+Pgz/zcyt8Z0HeYmYpeNOsVmUl3rzesPvlg4+AayvNkrbnqX6RekMtcZE6wjlXErg964HAdJQxwP14sy89H1hneL3ec6roS7bzON+b2QRgZ6e0J5xzs/bY7Q280+DzAsf/Yh/RXgbuBdoFjp9jZo8H3rsSb6rHqvwFeNLM/gh8W2n9nYGfa26gkK/kwK6pi9QZmsVMREQkQul0uoiISIRSERcREYlQKuIiIiIRSkVcREQkQqmIi4iIRCgVcRERkQilIi4iIhKhVMRFREQi1P8DJLBdV/CnaqgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def precision_recall_curve_plot(y_test , pred_proba_c1):\n",
    "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. \n",
    "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
    "    \n",
    "    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
    "    \n",
    "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    \n",
    "    # x축, y축 label과 legend, 그리고 grid 설정\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 스코어: 0.7805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score \n",
    "f1 = f1_score(y_test , pred)\n",
    "print('F1 스코어: {0:.4f}'.format(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    # F1 스코어 추가\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # f1 score print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "\n",
    "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5 ROC Curve와 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 추출을 위한 임곗값 배열의 index: [ 1  6 11 16 21 26 31 36 41 46 51]\n",
      "샘플 index로 추출한 임곗값:  [0.97 0.65 0.63 0.56 0.45 0.4  0.35 0.15 0.13 0.11 0.11]\n",
      "샘플 임곗값별 FPR:  [0.    0.017 0.034 0.076 0.127 0.169 0.203 0.466 0.585 0.686 0.797]\n",
      "샘플 임곗값별 TPR:  [0.033 0.639 0.721 0.754 0.803 0.836 0.885 0.902 0.934 0.967 0.984]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "# 반환된 임곗값 배열에서 샘플로 데이터를 추출하되, 임곗값을 5 Step으로 추출. \n",
    "# thresholds[0]은 max(예측확률)+1로 임의 설정됨. 이를 제외하기 위해 np.arange는 1부터 시작\n",
    "thr_index = np.arange(1, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index:', thr_index)\n",
    "print('샘플 index로 추출한 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, pred_proba_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01694915, 0.03389831, 0.07627119, 0.12711864,\n",
       "       0.16949153, 0.20338983, 0.46610169, 0.58474576, 0.68644068,\n",
       "       0.79661017])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fprs[thr_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53809542, 0.12138829, 0.12283432, 0.11728022, 0.14473469,\n",
       "       0.11773284, 0.11163588, 0.79098661, 0.21714386, 0.63043505,\n",
       "       0.10016387, 0.12507457, 0.12284031, 0.11168191, 0.56362471,\n",
       "       0.14110255, 0.09627488, 0.26659526, 0.27521556, 0.82808424,\n",
       "       0.24640791, 0.38057489, 0.1454692 , 0.18510983, 0.11205361,\n",
       "       0.23449365, 0.14030923, 0.07417881, 0.28042893, 0.304492  ,\n",
       "       0.94717778, 0.81734223, 0.12675564, 0.82593156, 0.39915358,\n",
       "       0.23449365, 0.07242159, 0.61109148, 0.05295729, 0.10396779,\n",
       "       0.35042987, 0.08339538, 0.82174594, 0.70763839, 0.63035192,\n",
       "       0.63036824, 0.91875624, 0.35865723, 0.94878994, 0.11208824,\n",
       "       0.59307077, 0.11168191, 0.13286775, 0.72506163, 0.30936861,\n",
       "       0.19701626, 0.22624902, 0.12283536, 0.15429962, 0.43221097,\n",
       "       0.28013641, 0.10081556, 0.54561047, 0.51347906, 0.4440903 ,\n",
       "       0.09464206, 0.6668253 , 0.59412582, 0.95181519, 0.14802789,\n",
       "       0.12897084, 0.1685566 , 0.10397004, 0.94792576, 0.19862072,\n",
       "       0.11168191, 0.3482516 , 0.18364519, 0.83555125, 0.12283536,\n",
       "       0.79480623, 0.64496666, 0.93086722, 0.13311725, 0.9489409 ,\n",
       "       0.9503937 , 0.15337069, 0.1254821 , 0.87441249, 0.11168191,\n",
       "       0.11168191, 0.23449365, 0.23226593, 0.11168191, 0.63036824,\n",
       "       0.07574735, 0.92875542, 0.10076469, 0.50567404, 0.96504608,\n",
       "       0.50167059, 0.0945974 , 0.94796772, 0.09758821, 0.52998868,\n",
       "       0.12844905, 0.14114971, 0.14802758, 0.44945163, 0.10772288,\n",
       "       0.11701177, 0.10894545, 0.40344622, 0.65372318, 0.11205361,\n",
       "       0.07106008, 0.12433694, 0.19839001, 0.92584293, 0.06868879,\n",
       "       0.11167303, 0.13065967, 0.06364362, 0.32166669, 0.01162154,\n",
       "       0.11167303, 0.11629217, 0.31666793, 0.67771455, 0.32140947,\n",
       "       0.96504608, 0.45380728, 0.73505661, 0.44241609, 0.56990521,\n",
       "       0.35067404, 0.74826731, 0.18622309, 0.10399526, 0.80313132,\n",
       "       0.90877528, 0.14802758, 0.11803817, 0.10130402, 0.09167393,\n",
       "       0.6676687 , 0.07570219, 0.23358933, 0.91812236, 0.1681733 ,\n",
       "       0.42852454, 0.63147194, 0.6366781 , 0.12277964, 0.77765856,\n",
       "       0.8808482 , 0.48756924, 0.13303157, 0.75139819, 0.69036922,\n",
       "       0.14986762, 0.7927972 , 0.09131253, 0.66675764, 0.38023185,\n",
       "       0.6513216 , 0.88398398, 0.30891805, 0.09169325, 0.89298182,\n",
       "       0.11163588, 0.85426687, 0.2503672 , 0.24020843, 0.40062394,\n",
       "       0.06233064, 0.14115674, 0.5450424 , 0.62676245])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_class1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "print('max predict_proba:', np.max(pred_proba_class1))\n",
    "\n",
    "fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "print('thresholds[0]:', thresholds[0])\n",
    "# 반환된 임곗값 배열 로우가 47건이므로 샘플로 10건만 추출하되, 임곗값을 5 Step으로 추출. \n",
    "thr_index = np.arange(0, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot(y_test , pred_proba_c1):\n",
    "    # 임곗값에 따른 FPR, TPR 값을 반환 받음. \n",
    "    fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)\n",
    "\n",
    "    # ROC Curve를 plot 곡선으로 그림. \n",
    "    plt.plot(fprs , tprs, label='ROC')\n",
    "    # 가운데 대각선 직선을 그림. \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    \n",
    "    # FPR X 축의 Scale을 0.1 단위로 변경, X,Y 축명 설정등   \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.xlim(0,1); plt.ylim(0,1)\n",
    "    plt.xlabel('FPR( 1 - Sensitivity )'); plt.ylabel('TPR( Recall )')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "### 아래는 roc_auc_score()의 인자를 잘못 입력한 것으로, 책에서 수정이 필요한 부분입니다. \n",
    "### 책에서는 roc_auc_score(y_test, pred)로 예측 타겟값을 입력하였으나 \n",
    "### roc_auc_score(y_test, y_score)로 y_score는 predict_proba()로 호출된 예측 확률 ndarray중 Positive 열에 해당하는 ndarray입니다. \n",
    "\n",
    "#pred = lr_clf.predict(X_test)\n",
    "#roc_score = roc_auc_score(y_test, pred)\n",
    "\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "roc_score = roc_auc_score(y_test, pred_proba)\n",
    "print('ROC AUC 값: {0:.4f}'.format(roc_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "          F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
